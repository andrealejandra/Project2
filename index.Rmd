---
title: 'Project 2: Data Mining, Classification, Prediction'
author: "SDS322E"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))

class_diag <- function(score, truth, positive, cutoff=.5){

  pred <- factor(score>cutoff,levels=c("TRUE","FALSE"))
  truth <- factor(truth==positive, levels=c("TRUE","FALSE"))

  tab<-table(truth, pred)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[1,1]/rowSums(tab)[1]
  spec=tab[2,2]/rowSums(tab)[2]
  ppv=tab[1,1]/colSums(tab)[1]

#CALCULATE F1
  f1=2*(sens*ppv)/(sens+ppv)
  
#CALCULATE EXACT AUC
  truth<-as.numeric(truth=="TRUE")
  ord<-order(score, decreasing=TRUE)
  score <- score[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(score[-1]>=score[-length(score)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  round(data.frame(acc,sens,spec,ppv,f1,ba=(sens+spec)/2,auc, row.names = "Metrics"),4)
}
```

# Mining, Classification, Prediction

## Andrea Virgen AAV782

### Introduction 

This dataset is a collection of personal information collected from an Oura ring, which is a wearable bio tracker that collects data on sleep, heart rate, breathing rate, body temperature, and activity. Oura software uses this information to calculate scores that are meant to inform the user of their sleep quality and how it effects their other bio metrics. This ring was worn daily for 221 days. 

I will use various methods to predict whether a standard deviation is above or below the mean categorized by Increase and Decrease, respectively. There are 73 observations above the mean temperature and 103 observations below the mean.


```{R}
library(tidyverse)
library(readr)

biotrends <- read_csv("~/HW SDS 322E/project2/oura_2020-12-05_2021-12-05_trends.csv")

#remove scores, NA values, and days with non-wear time
biotrends %>%
  select(-c(2:9,20:22,28:34,48:56)) %>%
  na.omit() %>%
  filter(`Non-wear Time`== 0) -> biotrends

biotrends %>%
  select(c(4:5,10,14:16,20,28)) -> bioanalysis

#create binary var
bioanalysis %>%
  mutate(`Temperature` = ifelse(`Temperature Deviation (Â°C)`>0, "Increase", "Decrease")) %>%
  select(-5) -> bioanalysis

table(bioanalysis$Temperature)

```

### Cluster Analysis

```{R}
library(cluster)
library(GGally)

# create subset of just numeric variables
bioanalysis %>%
  select_if(is.numeric) -> bio_num
#scale variables
bio_scale <- data.frame(scale(bio_num))

# calculate silhouette width and pick # of clusters
sil_width<-vector()
for(i in 2:10){
  pam_fit <- pam(bio_scale, k = i)  
  sil_width[i] <- pam_fit$silinfo$avg.width
}
ggplot()+geom_line(aes(x=1:10,y=sil_width))+scale_x_continuous(name="k",breaks=1:10)

# pam w/ 3 clusters
bio_scale %>%
  pam(k=2) -> bio_pam

#results of pam
bio_pam

plot(bio_pam,which=2)
# visualize clusters in ggpairs
bio_scale %>%
  mutate(cluster=as.factor(bio_pam$clustering)) %>%
  ggpairs(columns = c(1:7), aes(color=cluster))

```
To determine the amount of clusters that is most reasonable for my dataset, I plotted silhouette widths for amount of clusters ranging from 2 to 10. The largest width was for 2 clusters with an average width of .19, but this does not reflect any significant structure within the dataset. The medoids were partitioned around data point 65 for cluster 1 and data point 103

Red and blue clusters(1 and 2, respectively) show the most distinction in variables Awake Time and REM Sleep Time. Cluster 1 encompasses lower Awake Time and REM Sleep Values as well as lowest Average HRV(Heart Rate Variability) values. Steps and Average MET have the strongest positive correlation in both clusters, and this is expected because steps are a form of physical expenditure. Average MET is the average metabolic equivalent where one MET would mean an individual is only expending enough metabolic energy to fuel their basal metabolic processes. Cluster 2(blue) shows the next strongest correlation and shows a negative relationship between Sleep Latency and REM Sleep Time. This is reasonable considering increased Sleep Latency should allow more opportunity for REM Sleep Time, and this finding is bolstered by the the third strongest positive correlation between Sleep Latency and Awake Time in cluster 2.

There were a few unexpected correlations: Average HRV showed a small positive correlation with Sleep Latency in cluster 2, Average MET and Awake Time were slightly negatively correlated in cluster 1, Respiratory Rate and Sleep Latency showed a slight negative correlation in cluster 2, and Respiratory Rate and Average HRV showed another slight negative correlation in cluster 2.

    
    
### Dimensionality Reduction with PCA

```{R}

# eig1<- bio %>% cor %>% eigen()
# eig1$vectors

# conduct pca with scaled data
bio_pca <- princomp(bio_scale)
summary(bio_pca, loadings=T)

# save eigen values and varience proportion for scree plot
eigval<-bio_pca$sdev^2
varprop=round(eigval/sum(eigval), 2)

# can compare these two and only keep PCs where eigval > 1
# eigval for each PC shows the correlation for each variable across the PC axis
eigval
varprop

ggplot() + geom_bar(aes(y=varprop, x=1:7), stat="identity") + xlab("") + geom_path() +
  geom_text(aes(x=1:7, y=varprop, label=round(varprop, 2)), vjust=1, col="white")+
  scale_y_continuous(breaks=seq(0, .6, .2), labels = scales::percent) + 
  scale_x_continuous(breaks=1:10)
```
In my PCA analysis of the numerical variables in my dataset, the scree plot was not helpful in trying to determine which Principle Components should be kept. I decided to look at PC 1-3 because they all have a Standard Deviation above 1 and account of a cumulative proportion of 70.2% of the variance across the 7 scaled, numeric variables. I decided to leave out the extra ~17% cumulative proportion accounted for in PC 4 because the limited interpretation accounting for only an extra ~14% of variance seemed unnecessary.

PC 1 showed the strongest negative correlations in the variables Steps and Average MET at approximately -.61 each. This PC also showed a negative correlation of -.31 in Average HRV(Heart Rate Variability).

PC2 showed the most positive relationships out of the 3 Principle Components.

###  Linear Classifier

```{R}
# may not need this
bioanalysis %>%
  mutate(Temp = ifelse(Temperature == "Increase", 1, 0)) -> bio_glm

# fit linear model to temperature calculated by vars
fit <- glm(Temp ~ `REM Sleep Time` + `Awake Time` + `Sleep Latency` + `Average HRV` + `Respiratory Rate` + `Steps` + `Average MET`, data=bio_glm, family="binomial")

# prediction scores for each Temperature calculated from vars
score <- predict(fit, type="response")

# compute scores for glm
class_diag(score,truth=bio_glm$Temp, positive= 1)

# confusion matrix
# increases are more likely to be predicted by this model
table(truth = bioanalysis$Temperature, prediction = score>.5)
```

```{R}
# cross-validation of linear classifier here w/ folds
k=10 #choose number of folds
data<-bio_glm[sample(nrow(bio_glm)),] #randomly order rows
folds<-cut(seq(1:nrow(bio_glm)),breaks=k,labels=F) #create 10 folds
diags<-NULL
for(i in 1:k){
  ## Create training and test sets
  train<-data[folds==i,] 
  test<-data[folds==i,]
  truth<-test$Temp
  ## Train model on training set
  fit<-glm(Temp~(.)^2,data=train,family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  ## Test model on test set (save all k results)
  diags<-rbind(diags,class_diag(probs,truth, positive=1))
}

summarize_all(diags,mean)
```


Discussion here

### Non-Parametric Classifier

```{R}
library(caret)
# non-parametric classifier code here
```

```{R}
# cross-validation of np classifier here
```

Discussion


### Regression/Numeric Prediction

```{R}
# regression model code here
```

```{R}
# cross-validation of regression model here
```

Discussion

### Python 

```{R}
library(reticulate)
```

```{python}
# python code here
```

Discussion

### Concluding Remarks

I would like to conduct a follow-up analysis with a full year's worth of data to see if the insights change with more data points. Adding another categorical variable that measures self-perceived wellness would be another interesting facet to add and potentially predict. I would hypothesize a self-rated feeling from 1-5 would show an increased likelihood of temperature deviation above the norm, negative correlation with lowered sleep latency, and postive correlation with Average Heart Rate Variability.




